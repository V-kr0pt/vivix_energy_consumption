{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.neighbors import KNeighborsRegressor as knr\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.model_utils import Model_utils \n",
    "from utils.preprocess import LoadData \n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and preprocess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGboost and RF models will use the same preprocess pipeline (what can be explained by both are tree-based models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data = LoadData()\n",
    "\n",
    "# lagging columns\n",
    "lag_columns_list = ['medio_diario']*7\n",
    "lag_values = [1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "# load train/validation data\n",
    "data = load_data.data\n",
    "\n",
    "# create the lagged columns in data\n",
    "data = load_data.create_lag_columns(data, lag_columns_list, lag_values)\n",
    "data = data.iloc[7:]\n",
    "\n",
    "features = load_data.features\n",
    "target = load_data.target\n",
    "\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "\n",
    "# Scale is not needed for XGBoost (it is a tree-based model)\n",
    "preprocessor = load_data.create_preprocessor(scale_std=False, scale_minmax=False)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comments to be saved in the history\n",
    "comments = 'best xgboost removing last month data before shuffle'\n",
    "\n",
    "# Train the model\n",
    "model_name = 'xgboost' #name the model to save it in models + the metrics in history.csv\n",
    "\n",
    "# Create the XGBRegressor model\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror', enable_categorical='True',\n",
    "                         n_estimators= 1300, max_depth= 3, learning_rate= 0.01, \n",
    "                         gamma= 0, subsample= 0.3, reg_alpha= 0.5, \n",
    "                         reg_lambda= 0, random_state= 42, device='cuda'\n",
    "                         )\n",
    "\n",
    "model_utils = Model_utils()\n",
    "\n",
    "# Train the model with the best parameters\n",
    "model_utils.train_model(model, X_train, y_train, model_name, preprocessor=preprocessor, grid_search=False, comments=comments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model with the best parameters + the preprocessor\n",
    "model, preprocessor = model_utils.load_model()\n",
    "\n",
    "# Preprocess the test data\n",
    "X_test = preprocessor.transform(X_test) \n",
    "\n",
    "# Test the model\n",
    "y_pred = model_utils.test_model(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_date = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\") # or '2024-06-26_21-06-25' \n",
    "model_utils.plot_predictions(X_test, y_test, model_name+'__'+model_date) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is like the validation step. But here we upload only the last month and seven days before it (this data is not into the training/validation data) to do a sequencial (in time) prediction and a simulation that what will be done in production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the data (it's not the preprocessing)\n",
    "load_data = LoadData()\n",
    "# load the test data\n",
    "test_data = load_data.last_month_data\n",
    "data_last_7_days = load_data.data.tail(7) # the last 7 days before the last month will be used as lagged features\n",
    "\n",
    "# Union the last 7 days data with the last month data\n",
    "test_data = pd.concat([data_last_7_days,test_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing here!\n",
    "\n",
    "# lag feature and create a dataframe to each model\n",
    "lag_columns_list = ['medio_diario']*7\n",
    "lag_values = [1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "test_data = load_data.create_lag_columns(test_data, lag_columns_list, lag_values)\n",
    "\n",
    "# removing the first 7 rows after lagging\n",
    "test_data = test_data.iloc[7:]\n",
    "\n",
    "# Define the features and targets\n",
    "X_test = test_data[load_data.features]\n",
    "y_test = test_data[load_data.target]\n",
    "\n",
    "# Preprocess the data (doing the inputation, scaling if it was used in training)\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model\n",
    "model_path=f'models/{model_name}__{model_date}.pkl'\n",
    "preprocessor_path = f'models/preprocessors/{model_name}__{model_date}_preprocessor.pkl'\n",
    "\n",
    "\n",
    "model, preprocessor = model_utils.load_model(model_path=model_path, preprocessor_path=preprocessor_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model prediction\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "display(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_utils.plot_predictions(X_test, y_test, model_name+'__'+model_date) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data = LoadData()\n",
    "\n",
    "# lagging columns\n",
    "lag_columns_list = ['medio_diario']*7\n",
    "lag_values = [1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "# load train/validation data\n",
    "data = load_data.data\n",
    "\n",
    "# create the lagged columns in data\n",
    "data = load_data.create_lag_columns(data, lag_columns_list, lag_values)\n",
    "data = data.iloc[7:]\n",
    "\n",
    "features = load_data.features\n",
    "target = load_data.target\n",
    "\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "\n",
    "# Scale is not needed for XGBoost (it is a tree-based model)\n",
    "preprocessor = load_data.create_preprocessor(scale_std=False, scale_minmax=False)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model_name = 'Random_Forest' \n",
    "\n",
    "# Create the Random Forest model\n",
    "model = RandomForestRegressor(n_estimators=400, max_depth=10, min_samples_split=2, min_samples_leaf=1, max_features='sqrt', random_state=42)\n",
    "model_utils = Model_utils()\n",
    "\n",
    "# Train the model with the best parameters\n",
    "model_utils.train_model(model, X_train, y_train, model_name, preprocessor=preprocessor, grid_search=False, comments=comments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model with the best parameters + the preprocessor\n",
    "model, preprocessor = model_utils.load_model()\n",
    "\n",
    "# Preprocess the test data (already preprocessed)\n",
    "X_test = preprocessor.transform(X_test) \n",
    "\n",
    "# Test the model\n",
    "y_pred = model_utils.test_model(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_date = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\") #'2024-06-26_21-15-21'\n",
    "model_utils.plot_predictions(X_test, y_test, model_name+'__'+model_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is like the validation step. But here we upload only the last month and seven days before it (this data is not into the training/validation data) to do a sequencial (in time) prediction and a simulation that what will be done in production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the data (it's not the preprocessing)\n",
    "load_data = LoadData()\n",
    "\n",
    "# load the test data\n",
    "test_data = load_data.last_month_data\n",
    "data_last_7_days = load_data.data.tail(7) # the last 7 days before the last month will be used as lagged features\n",
    "\n",
    "# Union the last 7 days data with the last month data\n",
    "test_data = pd.concat([data_last_7_days,test_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing here!\n",
    "\n",
    "# lag features\n",
    "lag_columns_list = ['medio_diario']*7\n",
    "lag_values = [1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "test_data = load_data.create_lag_columns(test_data, lag_columns_list, lag_values)\n",
    "\n",
    "# removing the first 7 rows after lagging\n",
    "test_data = test_data.iloc[7:]\n",
    "\n",
    "# Define the features and targets\n",
    "X_test = test_data[load_data.features]\n",
    "y_test = test_data[load_data.target]\n",
    "\n",
    "# Preprocess the data (doing the inputation, scaling if it was used in training)\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model\n",
    "model_path=f'models/{model_name}__{model_date}.pkl'\n",
    "preprocessor_path = f'models/preprocessors/{model_name}__{model_date}_preprocessor.pkl'\n",
    "\n",
    "\n",
    "model, preprocessor = model_utils.load_model(model_path=model_path, preprocessor_path=preprocessor_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model prediction\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "display(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_utils.plot_predictions(X_test, y_test, model_name+'__'+model_date) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load and preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data = LoadData()\n",
    "\n",
    "# load train/validation data\n",
    "data = load_data.data\n",
    "\n",
    "# lagging columns\n",
    "lag_columns_list = ['medio_diario']*7\n",
    "lag_values = [1, 2, 3, 4, 5, 6, 7]\n",
    "lag_columns_list += load_data.features\n",
    "lag_values += [1]*len(load_data.features)\n",
    "\n",
    "# create the lagged columns in data\n",
    "data = load_data.create_lag_columns(data, lag_columns_list, lag_values)\n",
    "data = data.iloc[7:]\n",
    "\n",
    "features = load_data.features\n",
    "target = load_data.target\n",
    "\n",
    "X = data[features]\n",
    "y = data[target]\n",
    "\n",
    "# Scale is not needed for XGBoost (it is a tree-based model)\n",
    "preprocessor = load_data.create_preprocessor(scale_std=True, scale_minmax=False)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain the train\n",
    "comments = 'best KNN model. Removed last month data before shuffle. lagging all features.'\n",
    "\n",
    "# Train the model\n",
    "model_name = 'KNN'\n",
    "\n",
    "# Create the KN-Regressor model\n",
    "model = knr(algorithm='auto', leaf_size=1, n_neighbors= 5, p=1, weights ='distance')\n",
    "\n",
    "model_utils = Model_utils()\n",
    "\n",
    "# Train the model with the best parameters\n",
    "#model_utils.train_model(model, X_train, y_train, model_name, preprocessor=preprocessor, grid_search=True, param_grid=param_grid, comments=comments)\n",
    "model_utils.train_model(model, X_train, y_train, model_name, preprocessor=preprocessor, grid_search=False, comments=comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model with the best parameters + the preprocessor\n",
    "model, preprocessor = model_utils.load_model()\n",
    "\n",
    "# Preprocess the test data\n",
    "X_test = preprocessor.transform(X_test) \n",
    "\n",
    "# Test the model\n",
    "y_pred = model_utils.test_model(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_date = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\") #'2024-06-27_13-41-11' \n",
    "model_utils.plot_predictions(X_test, y_test, model_name+'__'+model_date) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step is like the validation step. But here we upload only the last month and seven days before it (this data is not into the training/validation data) to do a sequencial (in time) prediction and a simulation that what will be done in production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the data (it's not the preprocessing)\n",
    "load_data = LoadData()\n",
    "# load the test data\n",
    "test_data = load_data.last_month_data\n",
    "data_last_7_days = load_data.data.tail(7) # the last 7 days before the last month will be used as lagged features\n",
    "\n",
    "# Union the last 7 days data with the last month data\n",
    "test_data = pd.concat([data_last_7_days,test_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing here!\n",
    "\n",
    "# lag features \n",
    "lag_columns_list = ['medio_diario']*7\n",
    "lag_values = [1, 2, 3, 4, 5, 6, 7]\n",
    "lag_columns_list += load_data.features\n",
    "lag_values += [1]*len(load_data.features)\n",
    "\n",
    "# create the lagged columns in data\n",
    "test_data = load_data.create_lag_columns(test_data, lag_columns_list, lag_values)\n",
    "\n",
    "# removing the first 7 rows after lagging\n",
    "test_data = test_data.iloc[7:]\n",
    "\n",
    "# Define the features and targets\n",
    "X_test = test_data[load_data.features]\n",
    "y_test = test_data[load_data.target]\n",
    "\n",
    "# Preprocess the data (doing the inputation, scaling if it was used in training)\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model\n",
    "model_path=f'models/{model_name}__{model_date}.pkl'\n",
    "preprocessor_path = f'models/preprocessors/{model_name}__{model_date}_preprocessor.pkl'\n",
    "\n",
    "\n",
    "model, preprocessor = model_utils.load_model(model_path=model_path, preprocessor_path=preprocessor_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model prediction\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "display(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_utils.plot_predictions(X_test, y_test, model_name+'__'+model_date) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
